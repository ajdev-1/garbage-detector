{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"garbage_detector.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVuTdIhNwnTT2gkIjB2vMk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IG9trKrM8O2Q"},"source":["### **Garbage detection project**\n","\n","This Colab Notebook shows a simple way on how to use the Tensorflow API to \n","detect custom objects from images.\n","\n","In my case I tried to detect garbage within images that contain glass, paper and alu objects. I've created necessary images myself. The images have been taken within my private household to create a realistic dataset for garbage detection in private households.\n","\n","Within this project I used my own Google Drive folders to synchronize between difference devices. This happens by mounting the Google Drive folders to this Colab Notebook."]},{"cell_type":"markdown","metadata":{"id":"gwFmlIsvn7by"},"source":["### 0.) **Setup the environment**\n","\n","\n","\n","1.   Load and install necessary packages (tf version 1.15.0 is needed here).\n","2.   Mount Colab Notebook to Google Drive folder.\n","\n"]},{"cell_type":"code","metadata":{"id":"K91QS58f1Nbd","executionInfo":{"status":"ok","timestamp":1605206852825,"user_tz":-60,"elapsed":556,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"5e97b108-76ca-4935-ca22-48519701b8f6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# How much hours are left for the current session?\n","\n","import time, psutil\n","Start = time.time()- psutil.boot_time()\n","Left= 12*3600 - Start\n","print('Time remaining for this session is: ', Left/3600)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time remaining for this session is:  11.981702216333813\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7atosn1ejomd","executionInfo":{"status":"ok","timestamp":1605431048686,"user_tz":-60,"elapsed":1219,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}}},"source":["# IMPORTS\n","from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","import re\n","import os\n","import io\n","import glob\n","import shutil\n","import urllib.request\n","import tarfile\n","import xml.etree.ElementTree as ET\n","\n","import cv2 \n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","from google.colab import files"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QcFXTWrnlCo","executionInfo":{"status":"ok","timestamp":1605431168585,"user_tz":-60,"elapsed":119393,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"697f5fdc-bef9-4561-ad3d-3827fa96d3ea","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Initial module installation\n","!pip install tensorflow==1.15.0\n","!pip install tf_slim\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools\n","!pip install lvis\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 51.8MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 49.5MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=b9bbea392037bb7d376fc4373397916fd7faf5dc3e45953cda0b4421d82ab469\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n","Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.29.21)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (2.8.1)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.18.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis) (4.1.2.30)\n","Installing collected packages: lvis\n","Successfully installed lvis-0.5.3\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 144786 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.3_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.3) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KmvXw130jRJI","executionInfo":{"status":"ok","timestamp":1605431169802,"user_tz":-60,"elapsed":117456,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"c2006286-d525-4d2d-c062-a2c5f5625786","colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow as tf\n","# Version 1.15.0 is required\n","print(tf.__version__)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yx_KtJNa_yyf","executionInfo":{"status":"ok","timestamp":1605429449812,"user_tz":-60,"elapsed":16209,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"0aed2c2e-6320-467a-8041-b5b3b3a5dd87","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"da7zRU-cALBx","executionInfo":{"status":"ok","timestamp":1605429450900,"user_tz":-60,"elapsed":16727,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"2438c667-0669-4b42-e967-d34cfe7d0272","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0On7V2fajloo"},"source":["### 1. ) ***Preprocess data***\n","\n","\n","\n","1.   Create a folder for test and train data each.\n","2.   Move a part of the image annotations from the dataset to the test folder and the rest to the train folder (I used a 1/3 - 2/3 split respectively).\n","3.   Create one CSV file for the train and test annotations respectively (from XML annotation files) plus a label map file.\n","4.   Clone the tensorflow model repository.\n","5.   Setup PATH variable to the `slim` directory of `tensorflow/models`\n","6.   Run protobuf compilers.\n","7.   Create tf record files (.record) for train and test data.\n"]},{"cell_type":"code","metadata":{"id":"Y0sKQsxLfLmq","executionInfo":{"status":"ok","timestamp":1605049070982,"user_tz":-60,"elapsed":697,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"dd403c3b-2421-42b7-b5ac-96a06afb87af","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RI7opb3WidCe"},"source":["!mkdir test_labels train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNJIVfzjij4A"},"source":["## Move to ./data dir\n","\n","# Move the first x annotations to test\n","!ls annotations/* | sort -R | head -37 | xargs -I{} mv {} test_labels/\n","\n","# Move the rest (401) to train\n","!ls annotations/* | xargs -I{} mv {} train_labels/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"erZjNZQollHe","executionInfo":{"status":"ok","timestamp":1605049174170,"user_tz":-60,"elapsed":43765,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"4fae50b4-3ffa-4214-f550-7ff57574533d","colab":{"base_uri":"https://localhost:8080/"}},"source":["## Move to ./data dir\n","\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S2U0jOZAXZif"},"source":[" **Setting up models folder and protoc compiler**"]},{"cell_type":"code","metadata":{"id":"sTqaRHy1nUo1"},"source":["# Get tensorflow models repo\n","!git clone https://github.com/tensorflow/models.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUhFLXpip_Nw","executionInfo":{"status":"ok","timestamp":1605171718394,"user_tz":-60,"elapsed":807,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"18c22140-8fd3-452e-8d61-0a7659b7b765","colab":{"base_uri":"https://localhost:8080/"}},"source":["# New data\n","%cd ../models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '../models/research/'\n","/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3cHIln2cpvE_","executionInfo":{"status":"ok","timestamp":1605207326197,"user_tz":-60,"elapsed":587,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"f183ec8d-bffb-4820-f47b-79329985c28f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# No new data\n","%cd ./models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: './models/research/'\n","/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H4DvN6ToYs8b"},"source":["# THIS NEEDS TO GET SPECIFIED EVERY TIME\n","# exports PYTHONPATH environment var with research and slim paths\n","os.environ['PYTHONPATH'] += ':./:./slim/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxjLjNaNBVav"},"source":["# Compile proto buffers\n","!protoc ./object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6l-jia7pmDu"},"source":["# Check if modelbuilder is working properly\n","!python3 ./object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVaZOrZZX2FY"},"source":["**End of setup**"]},{"cell_type":"code","metadata":{"id":"_SbjnnRIrhb7","executionInfo":{"status":"ok","timestamp":1605085802682,"user_tz":-60,"elapsed":70068,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"8d91beba-b05e-484f-d601-a1788d6aadf7","colab":{"base_uri":"https://localhost:8080/"}},"source":["## Move to ./data dir\n","\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","from object_detection.utils import dataset_util\n","\n","#change this to the base directory where your data/ is \n","data_base_url = '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/'\n","\n","#location of images\n","image_dir = data_base_url +'images/'\n","\n","def class_text_to_int(row_label):\n","  if row_label == 'Papiertonne':\n","    return 1\n","  if row_label == 'Gelber Sack':\n","    return 2\n","  if row_label == 'Glascontainer':\n","    return 3\n","  else:\n","    None\n","\n","def split(df, group):\n","  data = namedtuple('data', ['filename', 'object'])\n","  gb = df.groupby(group)\n","  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","  with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","    encoded_jpg = fid.read()\n","  \n","  encoded_jpg_io = io.BytesIO(encoded_jpg)\n","  image = Image.open(encoded_jpg_io)\n","  width, height = image.size\n","  filename = group.filename.encode('utf8')\n","  image_format = b'jpg'\n","  xmins = []\n","  xmaxs = []\n","  ymins = []\n","  ymaxs = []\n","  classes_text = []\n","  classes = []\n","\n","  for index, row in group.object.iterrows():\n","    xmins.append(row['xmin'] / width)\n","    xmaxs.append(row['xmax'] / width)\n","    ymins.append(row['ymin'] / height)\n","    ymaxs.append(row['ymax'] / height)\n","    classes_text.append(row['class'].encode('utf8'))\n","    classes.append(class_text_to_int(row['class']))\n","\n","  tf_example = tf.train.Example(features=tf.train.Features(feature={\n","    'image/height': dataset_util.int64_feature(height),\n","    'image/width': dataset_util.int64_feature(width),\n","    'image/filename': dataset_util.bytes_feature(filename),\n","    'image/source_id': dataset_util.bytes_feature(filename),\n","    'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","    'image/format': dataset_util.bytes_feature(image_format),\n","    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","    'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","  return tf_example\n","\n","#creates tfrecord for both csv's\n","for csv in ['train_labels', 'test_labels']:\n","  writer = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n","  path = os.path.join(image_dir)\n","  examples = pd.read_csv(data_base_url + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","    tf_example = create_tf_example(group, path)\n","    writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecords: /gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/train_labels.record\n","Successfully created the TFRecords: /gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vJW21zyUj1Bj"},"source":["### 2.) **Configure model and train it**\n","\n","\n","\n","1.   Specify model to use (`selected_model`)\n","2.   Load predefined model from the tensorflow repository and store it.\n","3.   Adjust the config file for that model to your needs (I compared Faster RCNN with MobileNet).\n","4.   Create a tunnel with `ngrok` to run the tensorboard from within this notebook.\n","5.   Start the training.\n","\n"]},{"cell_type":"code","metadata":{"id":"Y05fN4SZBBil"},"source":["# Some models to train on\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","    },\n","}\n","\n","# Select a model from `MODELS_CONFIG`.\n","# I chose ssd_mobilenet_v2 for this project, you could choose any\n","selected_model = 'ssd_mobilenet_v2'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lv_IiVuABDk9"},"source":["#the distination folder where the model will be saved\n","#change this if you have a different working dir\n","DEST_DIR = '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/pretrained_model'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#checks if the model has already been downloaded, download it otherwise\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the model and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtpBphhvCPPV"},"source":["#path to the sample config file\n","#!cat object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","!cat object_detection/samples/configs/faster_rcnn_inception_v2_coco.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3epNjWWQ3YpL","executionInfo":{"status":"ok","timestamp":1604772361580,"user_tz":-60,"elapsed":529,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"aa81b9a8-08ac-44e0-87bd-a423e60651d6","colab":{"base_uri":"https://localhost:8080/"}},"source":["## Config for faster rcnn\n","%%writefile object_detection/samples/configs/faster_rcnn_inception_v2_coco.config\n","\n","# Faster R-CNN with Inception v2, configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 3\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 600\n","        max_dimension: 1024\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_inception_v2'\n","      first_stage_features_stride: 16\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 1.0\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.0\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 1\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0002\n","          schedule {\n","            step: 900000\n","            learning_rate: .00002\n","          }\n","          schedule {\n","            step: 1200000\n","            learning_rate: .000002\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  gradient_clipping_by_norm: 10.0\n","  fine_tune_checkpoint: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/pretrained_model/model.ckpt\"\n","  from_detection_checkpoint: true\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the COCO dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/train_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/test_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting object_detection/samples/configs/faster_rcnn_inception_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D7uV6ucKCaOd","executionInfo":{"status":"ok","timestamp":1605207069048,"user_tz":-60,"elapsed":2794,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"4851d18a-132e-4e69-f5a5-4b8a8ab70f93","colab":{"base_uri":"https://localhost:8080/"}},"source":["#path to the config file\n","%%writefile object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","\n","# paste the content of the config file in the same cell here.\n","# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 3\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        #use_dropout: true\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 8\n","        max_total_detections: 8\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 32\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.01\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_contrast {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_rgb_to_gray {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_vertical_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_rotation90 {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_patch_gaussian {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/train_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 37\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  #max_evals: 10\n","  num_visualizations: 20\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/test_labels.record\"\n","  }\n","  label_map_path: \"/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"29NBi-vTEHmL","executionInfo":{"status":"ok","timestamp":1605207075935,"user_tz":-60,"elapsed":2371,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"b99da5e6-a0e8-4f77-b986-81f033464f11","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Getting tensorboard ready for colab\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-11-12 18:51:12--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.200.34.1, 54.85.41.146, 34.194.108.77, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.200.34.1|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.14’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  35.5MB/s    in 0.4s    \n","\n","2020-11-12 18:51:12 (35.5 MB/s) - ‘ngrok-stable-linux-amd64.zip.14’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"js31EchJETh8","executionInfo":{"status":"ok","timestamp":1605207077813,"user_tz":-60,"elapsed":760,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"26ece01e-75a9-44c4-aceb-99c50515723b","colab":{"base_uri":"https://localhost:8080/"}},"source":["#specify where the log files are stored and we configure a link to view Tensorboard\n","\n","#the logs that are created while training \n","LOG_DIR = \"training/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://e1ab9e95691c.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ZtHdR8TEyUf"},"source":["# Start the training... !!!\n","# MobileNet Config: \n","#--pipeline_config_path=/gdrive/My\\ Drive/Ausbildung/Studium/FOM/\\3\\.\\ Semester/Anwendungsfelder\\ Business\\ Analytics/Colab\\ Notebooks/garbage_detector/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","#--pipeline_config_path=/gdrive/My\\ Drive/Ausbildung/Studium/FOM/\\3\\.\\ Semester/Anwendungsfelder\\ Business\\ Analytics/Colab\\ Notebooks/garbage_detector/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config \\\n","!python3 object_detection/model_main.py \\\n","    --pipeline_config_path=/gdrive/My\\ Drive/Ausbildung/Studium/FOM/\\3\\.\\ Semester/Anwendungsfelder\\ Business\\ Analytics/Colab\\ Notebooks/garbage_detector/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --model_dir=training/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19EwkjVxlSq3"},"source":["stopp bei 31700"]},{"cell_type":"markdown","metadata":{"id":"m8Gn701okBVa"},"source":["### 3.) **Export model and start visual inference**\n","\n","\n","\n","1.   Specify the location where the exported inference graph should be stored.\n","2.   Export inference graph with Tensorflow API.\n","\n"]},{"cell_type":"code","metadata":{"id":"Fsdb-rBakeQX","executionInfo":{"status":"ok","timestamp":1605211498938,"user_tz":-60,"elapsed":673,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"a0127490-ec43-4a4d-99fb-40c3b4984306","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd ./models/research/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: './models/research/'\n","/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h6iJENYiaKxI"},"source":["#dir where the model will be saved\n","output_directory = './fine_tuned_model_mobilenet_my_data_v2_300x300_32000s'\n","\n","lst = os.listdir('training')\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join('training', last_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGPLflbPa3CS","outputId":"c4d1d185-8da6-49cc-a0f2-be01eac6c466","colab":{"base_uri":"https://localhost:8080/"}},"source":["# os.environ['PYTHONPATH'] += ':./:./slim/' has to be set\n","# MobileNet config\n","#/ssd_mobilenet_v2_coco.config \\\n","#/faster_rcnn_inception_v2_coco.config \\\n","\n","!python ./object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=/gdrive/My\\ Drive/Ausbildung/Studium/FOM/\\3\\.\\ Semester/Anwendungsfelder\\ Business\\ Analytics/Colab\\ Notebooks/garbage_detector/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W1112 20:05:04.113483 139630500751232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cbXoml72oW4x"},"source":["### 4.) **Start local inference**\n","\n","Code snippet that can be used locally togehter with e.g. a webcam to run inference.\n","\n"]},{"cell_type":"code","metadata":{"id":"VqhjZSXGoaXG"},"source":["# Code to run local inference with webcam\n","\n","# This code need to be executed next to the models/research/object_detection/utils folder for the utils import.\n","# Also the protobuf compiler needs to get installed locally and run against the protobuf files from the tensorflow repo.\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","from utils import label_map_util\n","from utils import visualization_utils as vis_util\n","\n","# path to the frozen graph:\n","PATH_TO_FROZEN_GRAPH = '/Users/aj/Google Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/pretrained_model/frozen_inference_graph.pb'\n","\n","# path to the label map\n","PATH_TO_LABEL_MAP = '/Users/aj/Google Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/data/label_map.pbtxt'\n","\n","# number of classes \n","NUM_CLASSES = 1\n","\n","cap = cv2.VideoCapture(0)\n","\n","#reads the frozen graph\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABEL_MAP)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","# Detection\n","with detection_graph.as_default():\n","    with tf.Session(graph=detection_graph) as sess:\n","        while True:\n","            # Read frame from camera\n","            ret, image_np = cap.read()\n","            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","            image_np_expanded = np.expand_dims(image_np, axis=0)\n","            # Extract image tensor\n","            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","            # Extract detection boxes\n","            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","            # Extract detection scores\n","            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","            # Extract detection classes\n","            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","            # Extract number of detections\n","            num_detections = detection_graph.get_tensor_by_name(\n","                'num_detections:0')\n","            # Actual detection.\n","            (boxes, scores, classes, num_detections) = sess.run(\n","                [boxes, scores, classes, num_detections],\n","                feed_dict={image_tensor: image_np_expanded})\n","            # Visualization of the results of a detection.\n","            vis_util.visualize_boxes_and_labels_on_image_array(\n","                image_np,\n","                np.squeeze(boxes),\n","                np.squeeze(classes).astype(np.int32),\n","                np.squeeze(scores),\n","                category_index,\n","                use_normalized_coordinates=True,\n","                line_thickness=3,\n","                )\n","        # Display output\n","            cv2.imshow('Gun Detection', cv2.resize(image_np, (1200, 800)))\n","            if cv2.waitKey(25) & 0xFF == ord('q'):\n","                cv2.destroyAllWindows()\n","                break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duYN2lKn_77L"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"1lAfoaqp_-gC"},"source":["### 5.) **Show attributes of the inference graphs**\n","\n","1.   Define all models that will get inspected.\n","2.   Use `graph_metrics.py` from the tensorflow API to extract metrics from the trained inference graphs.\n","[Link to the specific tensorflow blob](https://raw.githubusercontent.com/tensorflow/tensorflow/fe454464681b036ff7fed3e42c6bb541fa52dd7c/tensorflow/python/tools/graph_metrics.py)\n"]},{"cell_type":"code","metadata":{"id":"5iwQfSNDAEHF","executionInfo":{"status":"ok","timestamp":1605431178235,"user_tz":-60,"elapsed":392,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}}},"source":["RESEARCH_PATH = '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/'\n","\n","inference_graphs = {\n","  'Mobilenet own data v1': RESEARCH_PATH + 'fine_tuned_model_mobilenet_my_data_v1_300x300_31752s',\n","  'Mobilenet own data v2': RESEARCH_PATH + 'fine_tuned_model_mobilenet_my_data_v2_300x300_32000s',\n","  'Mobilenet trashnet data v1': RESEARCH_PATH + 'fine_tuned_model_mobilenet_v1',\n","  'Mobilenet trashnet data v2': RESEARCH_PATH + 'fine_tuned_model_mobilenet_v2',\n","  'Faster RCNN trashnet data v1': RESEARCH_PATH + 'fine_tuned_model_rcnn_v1'   \n","}"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKqW8lH2DA3J"},"source":["for model, path in inference_graphs.items():\n","  print(f'Extracting attributes of inference graph for model {model}... \\n')\n","\n","  frozen_inference_graph = path + '/frozen_inference_graph.pb'\n","  #--graph frozen_inference_graph \\\n","\n","  !python '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/tools/graph_metrics.py' \\\n","    --graph '/gdrive/My Drive/Ausbildung/Studium/FOM/3. Semester/Anwendungsfelder Business Analytics/Colab Notebooks/garbage_detector/models/research/fine_tuned_model_mobilenet_my_data_v2_300x300_32000s/frozen_inference_graph.pb' \\\n","    --statistics=weight_parameters,flops\n","\n","  print('\\n\\n\\n')"],"execution_count":null,"outputs":[]}]}