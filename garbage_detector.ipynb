{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"garbage_detector.ipynb","provenance":[],"collapsed_sections":["gwFmlIsvn7by","0On7V2fajloo","vJW21zyUj1Bj","m8Gn701okBVa","cbXoml72oW4x"],"authorship_tag":"ABX9TyOUdtS8E3R/+QtxEZayFK9J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IG9trKrM8O2Q"},"source":["### **Garbage detection project**\n","\n","This Colab Notebook shows a simple way on how to use the Tensorflow API to \n","detect custom objects from images.\n","\n","In my case I tried to detect garbage within images that contain glass, paper and alu objects. I've created necessary images myself. The images have been taken within my private household to create a realistic dataset for garbage detection in private households.\n","\n","Within this project I used my own Google Drive folders to synchronize between difference devices. This happens by mounting the Google Drive folders to this Colab Notebook.\n","\n","\n","---\n","\n","\n","**Project folder structure**\n","\n","garbage_detector  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- data  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- annotations  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- images  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- train_labels  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- test_labels  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- train_labels.csv  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- test_labels.csv  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- train_labels.records  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- test_labels.records  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- label_map.pbtxt  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  \n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- (tensorflow/) models\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gwFmlIsvn7by"},"source":["### 0.) **Setup the environment**\n","\n","\n","\n","1.   Load and install necessary packages (tf version 1.15.0 is needed here).\n","2.   Mount Colab Notebook to Google Drive folder.\n","\n"]},{"cell_type":"code","metadata":{"id":"K91QS58f1Nbd"},"source":["# How much hours are left for the current session?\n","\n","import time, psutil\n","Start = time.time()- psutil.boot_time()\n","Left= 12*3600 - Start\n","print('Time remaining for this session is: ', Left/3600)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7atosn1ejomd"},"source":["# IMPORTS\n","from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","import re\n","import os\n","import io\n","import glob\n","import shutil\n","import urllib.request\n","import tarfile\n","import xml.etree.ElementTree as ET\n","\n","import cv2 \n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QcFXTWrnlCo"},"source":["# Initial module installation\n","!pip install tensorflow==1.15.0\n","!pip install tf_slim\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools\n","!pip install lvis\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmvXw130jRJI"},"source":["import tensorflow as tf\n","# Version 1.15.0 is required\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yx_KtJNa_yyf"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da7zRU-cALBx"},"source":["%cd 'PATH_TO_PROJECT'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0On7V2fajloo"},"source":["### 1. ) ***Preprocess data***\n","\n","\n","\n","1.   Create a folder for test and train data each.\n","2.   Move a part of the image annotations from the dataset to the test folder and the rest to the train folder (I used a 1/3 - 2/3 split respectively).\n","3.   Create one CSV file for the train and test annotations respectively (from XML annotation files) plus a label map file.\n","4.   Clone the tensorflow model repository.\n","5.   Setup PATH variable to the `slim` directory of `tensorflow/models`\n","6.   Run protobuf compilers.\n","7.   Create tf record files (.record) for train and test data.\n"]},{"cell_type":"code","metadata":{"id":"Y0sKQsxLfLmq"},"source":["%cd data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RI7opb3WidCe"},"source":["!mkdir test_labels train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNJIVfzjij4A"},"source":["## Move to ./data dir\n","\n","# Move the first x annotations to test\n","!ls annotations/* | sort -R | head -37 | xargs -I{} mv {} test_labels/\n","\n","# Move the rest (401) to train\n","!ls annotations/* | xargs -I{} mv {} train_labels/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"erZjNZQollHe","executionInfo":{"status":"ok","timestamp":1605049174170,"user_tz":-60,"elapsed":43765,"user":{"displayName":"aei jaei","photoUrl":"https://lh5.googleusercontent.com/-b8ST9D7lDxE/AAAAAAAAAAI/AAAAAAAAAQE/iUo40MnwzNI/s64/photo.jpg","userId":"13764316667525821619"}},"outputId":"4fae50b4-3ffa-4214-f550-7ff57574533d","colab":{"base_uri":"https://localhost:8080/"}},"source":["## Move to ./data dir\n","\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S2U0jOZAXZif"},"source":[" **Setting up models folder and protoc compiler**"]},{"cell_type":"code","metadata":{"id":"sTqaRHy1nUo1"},"source":["# Get tensorflow models repo\n","!git clone https://github.com/tensorflow/models.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cHIln2cpvE_"},"source":["# No new data\n","%cd ./models/research/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4DvN6ToYs8b"},"source":["# THIS NEEDS TO GET SPECIFIED EVERY TIME\n","# exports PYTHONPATH environment var with research and slim paths\n","os.environ['PYTHONPATH'] += ':./:./slim/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxjLjNaNBVav"},"source":["# Compile proto buffers\n","!protoc ./object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6l-jia7pmDu"},"source":["# Check if modelbuilder is working properly\n","!python3 ./object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVaZOrZZX2FY"},"source":["**End of setup**"]},{"cell_type":"code","metadata":{"id":"_SbjnnRIrhb7"},"source":["## Move to ./data dir\n","\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","from object_detection.utils import dataset_util\n","\n","#change this to the base directory where your data/ is \n","data_base_url = 'PATH_TO_PROJECT_DATA_FOLDER'\n","\n","#location of images\n","image_dir = data_base_url +'images/'\n","\n","def class_text_to_int(row_label):\n","  if row_label == 'label 1':\n","    return 1\n","  if row_label == 'label 2':\n","    return 2\n","  if row_label == 'label 3':\n","    return 3\n","  else:\n","    None\n","\n","def split(df, group):\n","  data = namedtuple('data', ['filename', 'object'])\n","  gb = df.groupby(group)\n","  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","  with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","    encoded_jpg = fid.read()\n","  \n","  encoded_jpg_io = io.BytesIO(encoded_jpg)\n","  image = Image.open(encoded_jpg_io)\n","  width, height = image.size\n","  filename = group.filename.encode('utf8')\n","  image_format = b'jpg'\n","  xmins = []\n","  xmaxs = []\n","  ymins = []\n","  ymaxs = []\n","  classes_text = []\n","  classes = []\n","\n","  for index, row in group.object.iterrows():\n","    xmins.append(row['xmin'] / width)\n","    xmaxs.append(row['xmax'] / width)\n","    ymins.append(row['ymin'] / height)\n","    ymaxs.append(row['ymax'] / height)\n","    classes_text.append(row['class'].encode('utf8'))\n","    classes.append(class_text_to_int(row['class']))\n","\n","  tf_example = tf.train.Example(features=tf.train.Features(feature={\n","    'image/height': dataset_util.int64_feature(height),\n","    'image/width': dataset_util.int64_feature(width),\n","    'image/filename': dataset_util.bytes_feature(filename),\n","    'image/source_id': dataset_util.bytes_feature(filename),\n","    'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","    'image/format': dataset_util.bytes_feature(image_format),\n","    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","    'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","  return tf_example\n","\n","#creates tfrecord for both csv's\n","for csv in ['train_labels', 'test_labels']:\n","  writer = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n","  path = os.path.join(image_dir)\n","  examples = pd.read_csv(data_base_url + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","    tf_example = create_tf_example(group, path)\n","    writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJW21zyUj1Bj"},"source":["### 2.) **Configure model and train it**\n","\n","\n","\n","1.   Specify model to use (`selected_model`)\n","2.   Load predefined model from the tensorflow repository and store it.\n","3.   Adjust the config file for that model to your needs (I compared Faster RCNN with MobileNet).\n","4.   Create a tunnel with `ngrok` to run the tensorboard from within this notebook.\n","5.   Start the training.\n","\n"]},{"cell_type":"code","metadata":{"id":"Y05fN4SZBBil"},"source":["# Some models to train on\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","    },\n","}\n","\n","# Select a model from `MODELS_CONFIG`.\n","# I chose ssd_mobilenet_v2 for this project, you could choose any\n","selected_model = 'ssd_mobilenet_v2'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lv_IiVuABDk9"},"source":["#the distination folder where the model will be saved\n","#change this if you have a different working dir\n","DEST_DIR = 'PATH_TO_PROJECT_MODELS_RESEARCH_PRETRAINEDMODEL_FOLDER'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#checks if the model has already been downloaded, download it otherwise\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the model and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtpBphhvCPPV"},"source":["# Path to the sample config file\n","# -> Get for example one of these configs and overwrite them with your prefered params\n","!cat object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","!cat object_detection/samples/configs/faster_rcnn_inception_v2_coco.config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29NBi-vTEHmL"},"source":["# Getting tensorboard ready for colab\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"js31EchJETh8"},"source":["#specify where the log files are stored and we configure a link to view Tensorboard\n","\n","#the logs that are created while training \n","LOG_DIR = \"training/\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZtHdR8TEyUf"},"source":["# Start the training\n","!python3 object_detection/model_main.py \\\n","    --pipeline_config_path='PATH_TO_CONFIG'\n","    --model_dir=training/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m8Gn701okBVa"},"source":["### 3.) **Export model and start visual inference**\n","\n","\n","\n","1.   Specify the location where the exported inference graph should be stored.\n","2.   Export inference graph with Tensorflow API.\n","\n"]},{"cell_type":"code","metadata":{"id":"Fsdb-rBakeQX"},"source":["%cd ./models/research/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6iJENYiaKxI"},"source":["#dir where the model will be saved\n","output_directory = 'PATH_FOR_MODEL_OUTPUT'\n","\n","lst = os.listdir('training')\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join('training', last_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGPLflbPa3CS"},"source":["!python ./object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path='PATH_TO_CONFIG'\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbXoml72oW4x"},"source":["### 4.) **Start local inference**\n","\n","Code snippet that can be used locally togehter with e.g. a webcam to run inference.\n","\n"]},{"cell_type":"code","metadata":{"id":"VqhjZSXGoaXG"},"source":["# Code to run local inference with webcam\n","\n","# This code need to be executed next to the models/research/object_detection/utils folder for the utils import.\n","# Also the protobuf compiler needs to get installed locally and run against the protobuf files from the tensorflow repo.\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","from utils import label_map_util\n","from utils import visualization_utils as vis_util\n","\n","# path to the frozen graph:\n","PATH_TO_FROZEN_GRAPH = ''\n","\n","# path to the label map\n","PATH_TO_LABEL_MAP = ''\n","\n","# number of classes \n","NUM_CLASSES = 1\n","\n","cap = cv2.VideoCapture(0)\n","\n","#reads the frozen graph\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABEL_MAP)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","# Detection\n","with detection_graph.as_default():\n","    with tf.Session(graph=detection_graph) as sess:\n","        while True:\n","            # Read frame from camera\n","            ret, image_np = cap.read()\n","            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","            image_np_expanded = np.expand_dims(image_np, axis=0)\n","            # Extract image tensor\n","            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","            # Extract detection boxes\n","            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","            # Extract detection scores\n","            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","            # Extract detection classes\n","            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","            # Extract number of detections\n","            num_detections = detection_graph.get_tensor_by_name(\n","                'num_detections:0')\n","            # Actual detection.\n","            (boxes, scores, classes, num_detections) = sess.run(\n","                [boxes, scores, classes, num_detections],\n","                feed_dict={image_tensor: image_np_expanded})\n","            # Visualization of the results of a detection.\n","            vis_util.visualize_boxes_and_labels_on_image_array(\n","                image_np,\n","                np.squeeze(boxes),\n","                np.squeeze(classes).astype(np.int32),\n","                np.squeeze(scores),\n","                category_index,\n","                use_normalized_coordinates=True,\n","                line_thickness=3,\n","                )\n","        # Display output\n","            cv2.imshow('x', cv2.resize(image_np, (1200, 800)))\n","            if cv2.waitKey(25) & 0xFF == ord('q'):\n","                cv2.destroyAllWindows()\n","                break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duYN2lKn_77L"},"source":[""]}]}